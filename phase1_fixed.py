#!/usr/bin/env python3
"""
================================================================================
SHIFAMIND PHASE 1 FIXED: Learnable Cross-Attention + Concept Grounding
================================================================================
Author: Mohammed Sameer Syed (Fixed Version)
University of Arizona - MS in AI Capstone

CRITICAL FIXES:
1. âœ… Learnable adaptive gates (content-dependent, not fixed)
2. âœ… Fine-tunable concept embeddings (contrastive learning)
3. âœ… Keyword attention supervision (force model to look at clinical terms)
4. âœ… Concept-diagnosis consistency loss (enforce alignment)
5. âœ… Joint training (not 3 separate stages)

Expected F1: >0.78 (beating vanilla BioClinicalBERT at 0.77)
================================================================================
"""

print("="*80)
print("ðŸš€ SHIFAMIND PHASE 1 FIXED - LEARNABLE CROSS-ATTENTION")
print("="*80)

# ============================================================================
# IMPORTS & SETUP
# ============================================================================

import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score
from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup

import json
from pathlib import Path
from tqdm.auto import tqdm
from typing import Dict, List
from collections import defaultdict, Counter
import pickle

SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nðŸ–¥ï¸  Device: {device}")

# ============================================================================
# CONFIGURATION
# ============================================================================

print("\n" + "="*80)
print("âš™ï¸  CONFIGURATION")
print("="*80)

BASE_PATH = Path('/content/drive/MyDrive/ShifaMind')
MIMIC_NOTES_PATH = BASE_PATH / '01_Raw_Datasets/Extracted/mimic-iv-note-2.2/note'
UMLS_META_PATH = BASE_PATH / '01_Raw_Datasets/Extracted/umls-2025AA-metathesaurus-full/2025AA/META'
MIMIC_PATH = BASE_PATH / '01_Raw_Datasets/Extracted/mimic-iv-3.1'

OUTPUT_BASE = BASE_PATH / '07_ShifaMind'
CHECKPOINT_PATH = OUTPUT_BASE / 'checkpoints/phase1_fixed'
RESULTS_PATH = OUTPUT_BASE / 'results/phase1_fixed'
SHARED_DATA_PATH = OUTPUT_BASE / 'shared_data'

CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)
RESULTS_PATH.mkdir(parents=True, exist_ok=True)

print(f"ðŸ“ Checkpoints: {CHECKPOINT_PATH}")
print(f"ðŸ“ Results: {RESULTS_PATH}")

TARGET_CODES = ['J189', 'I5023', 'A419', 'K8000']
ICD_DESCRIPTIONS = {
    'J189': 'Pneumonia, unspecified organism',
    'I5023': 'Acute on chronic systolic heart failure',
    'A419': 'Sepsis, unspecified organism',
    'K8000': 'Calculus of gallbladder with acute cholecystitis'
}

# Clinical keywords for attention supervision
DIAGNOSIS_KEYWORDS = {
    'J189': ['pneumonia', 'lung', 'respiratory', 'infiltrate', 'fever', 'cough', 'dyspnea', 'consolidation'],
    'I5023': ['heart', 'cardiac', 'failure', 'edema', 'dyspnea', 'orthopnea', 'bnp', 'cardiomyopathy'],
    'A419': ['sepsis', 'bacteremia', 'infection', 'fever', 'hypotension', 'shock', 'lactate', 'organ'],
    'K8000': ['cholecystitis', 'gallbladder', 'gallstone', 'abdominal', 'murphy', 'pain', 'biliary']
}

# Diagnosis-concept mapping for consistency loss
DIAGNOSIS_CONCEPTS = {
    'J189': ['pneumonia', 'lung infection', 'respiratory infection', 'infiltrate', 'dyspnea'],
    'I5023': ['heart failure', 'cardiac failure', 'edema', 'dyspnea', 'cardiomyopathy'],
    'A419': ['sepsis', 'bacteremia', 'infection', 'hypotension', 'shock'],
    'K8000': ['cholecystitis', 'gallbladder', 'gallstone', 'abdominal pain']
}

print(f"\nðŸŽ¯ Target: {len(TARGET_CODES)} diagnoses")

# ============================================================================
# LOAD SAVED SPLITS (From original Phase 1)
# ============================================================================

print("\n" + "="*80)
print("ðŸ“¥ LOADING SAVED SPLITS")
print("="*80)

with open(SHARED_DATA_PATH / 'train_split.pkl', 'rb') as f:
    df_train = pickle.load(f)
with open(SHARED_DATA_PATH / 'val_split.pkl', 'rb') as f:
    df_val = pickle.load(f)
with open(SHARED_DATA_PATH / 'test_split.pkl', 'rb') as f:
    df_test = pickle.load(f)

train_concept_labels = np.load(SHARED_DATA_PATH / 'train_concept_labels.npy')
val_concept_labels = np.load(SHARED_DATA_PATH / 'val_concept_labels.npy')
test_concept_labels = np.load(SHARED_DATA_PATH / 'test_concept_labels.npy')

print(f"âœ… Loaded:")
print(f"   Train: {len(df_train):,}")
print(f"   Val:   {len(df_val):,}")
print(f"   Test:  {len(df_test):,}")

# ============================================================================
# LOAD CONCEPT EMBEDDINGS
# ============================================================================

print("\n" + "="*80)
print("ðŸ§¬ LOADING CONCEPT EMBEDDINGS")
print("="*80)

tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
concept_embeddings_frozen = torch.load(SHARED_DATA_PATH / 'concept_embeddings.pt', map_location=device, weights_only=False)
num_concepts = concept_embeddings_frozen.shape[0]

print(f"âœ… Concept embeddings: {concept_embeddings_frozen.shape}")

# ============================================================================
# FIXED ARCHITECTURE
# ============================================================================

print("\n" + "="*80)
print("ðŸ—ï¸  FIXED ARCHITECTURE")
print("="*80)

class AdaptiveGatedCrossAttention(nn.Module):
    """FIX 1: Learnable, content-dependent gates"""
    def __init__(self, hidden_size, num_heads=8, dropout=0.1, layer_idx=1):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_heads = num_heads
        self.head_dim = hidden_size // num_heads

        self.query = nn.Linear(hidden_size, hidden_size)
        self.key = nn.Linear(hidden_size, hidden_size)
        self.value = nn.Linear(hidden_size, hidden_size)

        # FIX: Content-dependent gate (learns when concepts are relevant)
        self.gate_net = nn.Sequential(
            nn.Linear(hidden_size * 3, hidden_size),  # [text, context, relevance]
            nn.ReLU(),
            nn.Linear(hidden_size, 1),
            nn.Sigmoid()
        )

        self.out_proj = nn.Linear(hidden_size, hidden_size)
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(hidden_size)

    def forward(self, hidden_states, concept_embeddings, attention_mask=None):
        batch_size, seq_len, _ = hidden_states.shape
        num_concepts = concept_embeddings.shape[0]

        concepts_batch = concept_embeddings.unsqueeze(0).expand(batch_size, -1, -1)

        Q = self.query(hidden_states).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        K = self.key(concepts_batch).view(batch_size, num_concepts, self.num_heads, self.head_dim).transpose(1, 2)
        V = self.value(concepts_batch).view(batch_size, num_concepts, self.num_heads, self.head_dim).transpose(1, 2)

        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)
        attn_weights = F.softmax(scores, dim=-1)
        attn_weights = self.dropout(attn_weights)

        context = torch.matmul(attn_weights, V)
        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_size)
        context = self.out_proj(context)

        # FIX: Compute relevance score (cosine similarity between text and concepts)
        text_pooled = hidden_states.mean(dim=1)  # [batch, hidden]
        concept_pooled = concepts_batch.mean(dim=1)  # [batch, hidden]
        relevance = F.cosine_similarity(text_pooled, concept_pooled, dim=-1)  # [batch]
        relevance = relevance.unsqueeze(-1).unsqueeze(-1)  # [batch, 1, 1]
        relevance = relevance.expand(-1, seq_len, -1)  # [batch, seq, 1]
        relevance_features = relevance.expand(-1, -1, self.hidden_size)  # [batch, seq, hidden]

        # FIX: Gate based on text, context, AND relevance
        gate_input = torch.cat([hidden_states, context, relevance_features], dim=-1)
        gate_values = self.gate_net(gate_input)  # [batch, seq, 1]

        # Apply gate
        output = hidden_states + gate_values * context
        output = self.layer_norm(output)

        return output, attn_weights.mean(dim=1), gate_values.mean()

class ShifaMindPhase1Fixed(nn.Module):
    """FIX 2-4: Fine-tunable concepts, keyword supervision, consistency loss"""
    def __init__(self, base_model, concept_embeddings_init, num_classes, fusion_layers=[9, 11]):
        super().__init__()
        self.base_model = base_model
        self.hidden_size = base_model.config.hidden_size
        self.fusion_layers = fusion_layers

        # FIX 2: Make concept embeddings LEARNABLE
        self.concept_embeddings = nn.Parameter(concept_embeddings_init.clone())
        self.num_concepts = concept_embeddings_init.shape[0]

        # FIX 1: Adaptive gates
        self.fusion_modules = nn.ModuleDict({
            str(layer): AdaptiveGatedCrossAttention(self.hidden_size, layer_idx=layer)
            for layer in fusion_layers
        })

        self.diagnosis_head = nn.Linear(self.hidden_size, num_classes)
        self.concept_head = nn.Linear(self.hidden_size, self.num_concepts)
        self.dropout = nn.Dropout(0.1)

        print(f"   ðŸ”§ Learnable concept embeddings: {self.concept_embeddings.shape}")
        print(f"   ðŸ”§ Adaptive gates in layers: {fusion_layers}")
        print(f"   ðŸ“Š Parameters: {sum(p.numel() for p in self.parameters()):,}")

    def forward(self, input_ids, attention_mask, return_gates=False, return_attention=False):
        outputs = self.base_model(
            input_ids=input_ids, attention_mask=attention_mask,
            output_hidden_states=True, output_attentions=return_attention,
            return_dict=True
        )

        hidden_states = outputs.hidden_states
        current_hidden = outputs.last_hidden_state

        gate_values = []
        fusion_attentions = {}

        for layer_idx in self.fusion_layers:
            if str(layer_idx) in self.fusion_modules:
                layer_hidden = hidden_states[layer_idx]
                fused_hidden, attn, gate = self.fusion_modules[str(layer_idx)](
                    layer_hidden, self.concept_embeddings, attention_mask
                )
                current_hidden = fused_hidden
                gate_values.append(gate)
                if return_attention:
                    fusion_attentions[f'layer_{layer_idx}'] = attn

        cls_hidden = self.dropout(current_hidden[:, 0, :])
        diagnosis_logits = self.diagnosis_head(cls_hidden)
        concept_logits = self.concept_head(cls_hidden)

        result = {
            'logits': diagnosis_logits,
            'concept_scores': concept_logits,
            'cls_hidden': cls_hidden,
            'hidden_states': current_hidden
        }

        if return_gates:
            result['gate_values'] = torch.stack(gate_values).mean() if gate_values else torch.tensor(0.5)

        if return_attention:
            result['fusion_attentions'] = fusion_attentions
            result['base_attentions'] = outputs.attentions

        return result

print("âœ… Fixed architecture defined")

# ============================================================================
# FIX 3 & 4: ENHANCED LOSS FUNCTIONS
# ============================================================================

print("\n" + "="*80)
print("ðŸ”§ ENHANCED LOSS FUNCTIONS")
print("="*80)

class ComprehensiveLoss(nn.Module):
    """
    FIX 3: Keyword attention supervision
    FIX 4: Concept-diagnosis consistency
    """
    def __init__(self, diagnosis_weight=0.4, concept_weight=0.25,
                 keyword_weight=0.15, consistency_weight=0.2):
        super().__init__()
        self.bce = nn.BCEWithLogitsLoss()
        self.w_dx = diagnosis_weight
        self.w_concept = concept_weight
        self.w_keyword = keyword_weight
        self.w_consistency = consistency_weight

        print(f"   Diagnosis: {diagnosis_weight}")
        print(f"   Concept: {concept_weight}")
        print(f"   Keyword: {keyword_weight}")
        print(f"   Consistency: {consistency_weight}")

    def forward(self, outputs, dx_labels, concept_labels, keyword_mask=None):
        # Base losses
        loss_dx = self.bce(outputs['logits'], dx_labels)
        loss_concept = self.bce(outputs['concept_scores'], concept_labels)

        # FIX 3: Keyword attention supervision
        loss_keyword = torch.tensor(0.0, device=dx_labels.device)
        if keyword_mask is not None and 'fusion_attentions' in outputs:
            for layer_name, attn in outputs['fusion_attentions'].items():
                # attn: [batch, seq_len, num_concepts]
                # keyword_mask: [batch, seq_len]
                keyword_mask_expanded = keyword_mask.unsqueeze(-1)  # [batch, seq_len, 1]
                attn_on_keywords = (attn * keyword_mask_expanded).sum(dim=1)  # [batch, num_concepts]
                keyword_counts = keyword_mask.sum(dim=1, keepdim=True).clamp(min=1)  # [batch, 1]
                avg_attn_on_keywords = attn_on_keywords / keyword_counts  # [batch, num_concepts]
                loss_keyword += -avg_attn_on_keywords.mean()  # Maximize attention on keywords

        # FIX 4: Concept-diagnosis consistency
        # If diagnosis is positive, relevant concepts should be active
        # If diagnosis is negative, relevant concepts should be inactive
        dx_probs = torch.sigmoid(outputs['logits'])  # [batch, num_dx]
        concept_probs = torch.sigmoid(outputs['concept_scores'])  # [batch, num_concepts]

        # Penalize inconsistency: if dx is high but concepts are low (or vice versa)
        loss_consistency = torch.abs(dx_probs.unsqueeze(-1) - concept_labels.unsqueeze(1)).mean()

        total = (self.w_dx * loss_dx + self.w_concept * loss_concept +
                 self.w_keyword * loss_keyword + self.w_consistency * loss_consistency)

        return total, {
            'diagnosis': loss_dx.item(),
            'concept': loss_concept.item(),
            'keyword': loss_keyword.item() if torch.is_tensor(loss_keyword) else 0,
            'consistency': loss_consistency.item()
        }

criterion = ComprehensiveLoss()
print("âœ… Enhanced loss ready")

# ============================================================================
# DATASET WITH KEYWORD MASKING
# ============================================================================

class EnhancedDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, concept_labels, keywords_dict,
                 target_codes, max_length=384):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.concept_labels = concept_labels
        self.keywords_dict = keywords_dict
        self.target_codes = target_codes
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        encoding = self.tokenizer(
            text, padding='max_length', truncation=True,
            max_length=self.max_length, return_tensors='pt'
        )

        # Create keyword mask
        tokens = self.tokenizer.tokenize(text)
        keyword_mask = torch.zeros(self.max_length)

        # Find which diagnosis is present
        label_vec = self.labels[idx]
        for i, code in enumerate(self.target_codes):
            if label_vec[i] == 1:
                keywords = self.keywords_dict.get(code, [])
                for k, token in enumerate(tokens[:self.max_length]):
                    if any(kw in token.lower() for kw in keywords):
                        keyword_mask[k] = 1.0

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.FloatTensor(self.labels[idx]),
            'concept_labels': torch.FloatTensor(self.concept_labels[idx]),
            'keyword_mask': keyword_mask
        }

train_dataset = EnhancedDataset(
    df_train['text'].tolist(), df_train['labels'].tolist(), tokenizer,
    train_concept_labels, DIAGNOSIS_KEYWORDS, TARGET_CODES
)
val_dataset = EnhancedDataset(
    df_val['text'].tolist(), df_val['labels'].tolist(), tokenizer,
    val_concept_labels, DIAGNOSIS_KEYWORDS, TARGET_CODES
)
test_dataset = EnhancedDataset(
    df_test['text'].tolist(), df_test['labels'].tolist(), tokenizer,
    test_concept_labels, DIAGNOSIS_KEYWORDS, TARGET_CODES
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)
test_loader = DataLoader(test_dataset, batch_size=16)

print(f"\nâœ… Datasets ready (with keyword masking)")

# ============================================================================
# INITIALIZE FIXED MODEL
# ============================================================================

print("\n" + "="*80)
print("ðŸš€ INITIALIZING FIXED MODEL")
print("="*80)

base_model = AutoModel.from_pretrained("emilyalsentzer/Bio_ClinicalBERT").to(device)
model = ShifaMindPhase1Fixed(
    base_model=base_model,
    concept_embeddings_init=concept_embeddings_frozen,
    num_classes=len(TARGET_CODES),
    fusion_layers=[9, 11]
).to(device)

print(f"\nâœ… Model on {device}")

# ============================================================================
# JOINT TRAINING (FIX 6: No stages, train everything together)
# ============================================================================

print("\n" + "="*80)
print("ðŸ‹ï¸  JOINT TRAINING (No Stages)")
print("="*80)

optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
num_epochs = 5
scheduler = get_linear_schedule_with_warmup(
    optimizer, num_warmup_steps=len(train_loader) // 10,
    num_training_steps=len(train_loader) * num_epochs
)

best_f1 = 0
checkpoint_file = CHECKPOINT_PATH / 'phase1_fixed_best.pt'

for epoch in range(num_epochs):
    print(f"\n{'='*70}\nEpoch {epoch+1}/{num_epochs}\n{'='*70}")

    # Train
    model.train()
    total_loss = 0
    loss_components = defaultdict(float)
    gate_values_epoch = []

    for batch in tqdm(train_loader, desc="  Training"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)
        keyword_mask = batch['keyword_mask'].to(device)

        optimizer.zero_grad()

        outputs = model(input_ids, attention_mask, return_gates=True, return_attention=True)
        loss, components = criterion(outputs, labels, concept_labels, keyword_mask)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()

        total_loss += loss.item()
        for k, v in components.items():
            loss_components[k] += v

        if 'gate_values' in outputs:
            gate_values_epoch.append(outputs['gate_values'].item())

    avg_loss = total_loss / len(train_loader)
    avg_gate = np.mean(gate_values_epoch) if gate_values_epoch else 0.5

    print(f"\n  Loss: {avg_loss:.4f}")
    print(f"  Gate: {avg_gate:.4f}")
    for k in ['diagnosis', 'concept', 'keyword', 'consistency']:
        if k in loss_components:
            print(f"    {k}: {loss_components[k]/len(train_loader):.4f}")

    # Validate
    model.eval()
    all_preds, all_labels = [], []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="  Validating"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(input_ids, attention_mask)
            preds = torch.sigmoid(outputs['logits']).cpu().numpy()
            all_preds.append(preds)
            all_labels.append(labels.cpu().numpy())

    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)
    pred_binary = (all_preds > 0.5).astype(int)

    macro_f1 = f1_score(all_labels, pred_binary, average='macro', zero_division=0)
    print(f"\n  Val F1: {macro_f1:.4f}")

    if macro_f1 > best_f1:
        best_f1 = macro_f1
        torch.save({
            'model_state_dict': model.state_dict(),
            'concept_embeddings': model.concept_embeddings,
            'num_concepts': num_concepts,
            'macro_f1': best_f1,
            'epoch': epoch
        }, checkpoint_file)
        print(f"  âœ… Saved (F1: {best_f1:.4f})")

print(f"\nâœ… Training complete! Best F1: {best_f1:.4f}")

# ============================================================================
# FINAL EVALUATION
# ============================================================================

print("\n" + "="*80)
print("ðŸ“Š FINAL EVALUATION")
print("="*80)

checkpoint = torch.load(checkpoint_file, map_location=device, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])

model.eval()
all_preds, all_labels = [], []

with torch.no_grad():
    for batch in tqdm(test_loader, desc="  Testing"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        outputs = model(input_ids, attention_mask)
        preds = torch.sigmoid(outputs['logits']).cpu().numpy()
        all_preds.append(preds)
        all_labels.append(labels.cpu().numpy())

all_preds = np.vstack(all_preds)
all_labels = np.vstack(all_labels)
pred_binary = (all_preds > 0.5).astype(int)

macro_f1 = f1_score(all_labels, pred_binary, average='macro', zero_division=0)
micro_f1 = f1_score(all_labels, pred_binary, average='micro', zero_division=0)
macro_precision = precision_score(all_labels, pred_binary, average='macro', zero_division=0)
macro_recall = recall_score(all_labels, pred_binary, average='macro', zero_division=0)

try:
    macro_auc = roc_auc_score(all_labels, all_preds, average='macro')
except:
    macro_auc = 0.0

per_class_f1 = [f1_score(all_labels[:, i], pred_binary[:, i], zero_division=0)
                for i in range(len(TARGET_CODES))]

print("\n" + "="*80)
print("ðŸŽ‰ PHASE 1 FIXED - FINAL RESULTS")
print("="*80)

print("\nðŸŽ¯ Performance:")
print(f"   Macro F1:    {macro_f1:.4f}")
print(f"   Micro F1:    {micro_f1:.4f}")
print(f"   Precision:   {macro_precision:.4f}")
print(f"   Recall:      {macro_recall:.4f}")
print(f"   AUROC:       {macro_auc:.4f}")

print("\nðŸ“Š Per-Class F1:")
for i, code in enumerate(TARGET_CODES):
    print(f"   {code}: {per_class_f1[i]:.4f}")

# Compare to baselines
baseline_f1 = 0.7706  # BioClinicalBERT from Phase 4
improvement = macro_f1 - baseline_f1

print(f"\nðŸ”¥ VS BIOCLINICALBERT BASELINE:")
print(f"   Baseline:  {baseline_f1:.4f}")
print(f"   Phase 1 Fixed: {macro_f1:.4f}")
print(f"   Î”: {improvement:+.4f} ({improvement/baseline_f1*100:+.1f}%)")

if macro_f1 > 0.78:
    print("\nâœ… SUCCESS! Beat target (>0.78)")
elif macro_f1 > baseline_f1:
    print("\nâœ… IMPROVEMENT! Beat baseline")
else:
    print(f"\nðŸ“Š Gap to target: {0.78 - macro_f1:.4f}")

# Save results
results = {
    'phase': 'Phase 1 Fixed - Learnable Cross-Attention',
    'test_metrics': {
        'macro_f1': float(macro_f1),
        'micro_f1': float(micro_f1),
        'macro_precision': float(macro_precision),
        'macro_recall': float(macro_recall),
        'macro_auc': float(macro_auc),
        'per_class_f1': {code: float(f1) for code, f1 in zip(TARGET_CODES, per_class_f1)}
    },
    'comparison': {
        'baseline_f1': baseline_f1,
        'phase1_fixed_f1': float(macro_f1),
        'improvement': float(improvement),
        'improvement_pct': float(improvement/baseline_f1*100)
    },
    'fixes_applied': [
        'Learnable adaptive gates (content-dependent)',
        'Fine-tunable concept embeddings',
        'Keyword attention supervision',
        'Concept-diagnosis consistency loss',
        'Joint training (no stages)'
    ]
}

with open(RESULTS_PATH / 'phase1_fixed_results.json', 'w') as f:
    json.dump(results, f, indent=2)

# Save updated concept embeddings
torch.save(model.concept_embeddings, SHARED_DATA_PATH / 'concept_embeddings_fixed.pt')

print(f"\nðŸ’¾ Results: {RESULTS_PATH}")
print(f"ðŸ’¾ Checkpoint: {checkpoint_file}")
print(f"ðŸ’¾ Concept embeddings: {SHARED_DATA_PATH / 'concept_embeddings_fixed.pt'}")

print("\n" + "="*80)
print("âœ… PHASE 1 FIXED COMPLETE!")
print("="*80)
print(f"\nðŸ“ˆ Final Macro F1: {macro_f1:.4f}")
print("\nðŸš€ Ready for Phase 2 Fixed (Diagnosis-Aware RAG)")
print(f"\nAlhamdulillah! ðŸ¤²")
